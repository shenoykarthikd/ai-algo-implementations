{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EigenCam\n",
    "### Adapted & Modified from https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import AblationCAM, EigenCAM\n",
    "from pytorch_grad_cam.ablation_layer import AblationLayerFasterRCNN\n",
    "from pytorch_grad_cam.utils.model_targets import FasterRCNNBoxScoreTarget\n",
    "from pytorch_grad_cam.utils.reshape_transforms import fasterrcnn_reshape_transform\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_tensor, model, device, detection_threshold):\n",
    "    outputs = model(input_tensor)\n",
    "    pred_classes = [class_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "    pred_labels = outputs[0]['labels'].cpu().numpy()\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "    \n",
    "    boxes, classes, labels, indices, scores = [], [], [], [], []\n",
    "    for index in range(len(pred_scores)):\n",
    "        if pred_scores[index] >= detection_threshold:\n",
    "            boxes.append(pred_bboxes[index].astype(np.int32))\n",
    "            classes.append(pred_classes[index])\n",
    "            labels.append(pred_labels[index])\n",
    "            indices.append(index)\n",
    "            scores.append(pred_scores[index])\n",
    "    boxes = np.int32(boxes)\n",
    "    return boxes, classes, labels, indices, scores, outputs\n",
    "\n",
    "def draw_boxes(boxes, labels, classes, image):\n",
    "    for i, box in enumerate(boxes):\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            (220, 0, 0), 2\n",
    "        )\n",
    "        cv2.putText(image, classes[i], (int(box[0]), int(box[1] - 5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (220, 0, 0), 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"\"\n",
    "model_path = \"\"\n",
    "model_threshold = 0.7\n",
    "class_names = []\n",
    "\n",
    "\n",
    "img = cv2.imread(image_file)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image = np.array(img)\n",
    "image_float_np = np.float32(image) / 255\n",
    "# define the torchvision image transforms\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "input_tensor = transform(image)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_tensor = input_tensor.to(device)\n",
    "# Add a batch dimension:\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=num_classes, pretrained=False, pretrained_backbone=True)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval().to(device)\n",
    "\n",
    "# Run the model and display the detections\n",
    "boxes, classes, labels, indices, scores, outputs = predict(input_tensor, model, device, 0.9)\n",
    "image = draw_boxes(boxes, labels, classes, image)\n",
    "\n",
    "# Show the image:\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EigenCam - W/o Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.backbone]\n",
    "targets = [FasterRCNNBoxScoreTarget(labels=labels, bounding_boxes=boxes)]\n",
    "cam = EigenCAM(model,\n",
    "               target_layers, \n",
    "               use_cuda=torch.cuda.is_available(),\n",
    "               reshape_transform=fasterrcnn_reshape_transform)\n",
    "\n",
    "grayscale_cam = cam(input_tensor, targets=targets)\n",
    "# Take the first image in the batch:\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(image_float_np, grayscale_cam, use_rgb=True)\n",
    "# And lets draw the boxes again:\n",
    "image_with_bounding_boxes = draw_boxes(boxes, labels, classes, cam_image)\n",
    "Image.fromarray(image_with_bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EigenCam - W/ Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize_cam_in_bounding_boxes(boxes, image_float_np, grayscale_cam):\n",
    "    \"\"\"Normalize the CAM to be in the range [0, 1] \n",
    "    inside every bounding boxes, and zero outside of the bounding boxes. \"\"\"\n",
    "    renormalized_cam = np.zeros(grayscale_cam.shape, dtype=np.float32)\n",
    "    images = []\n",
    "    for x1, y1, x2, y2 in boxes:\n",
    "        img = renormalized_cam * 0\n",
    "        img[y1:y2, x1:x2] = scale_cam_image(grayscale_cam[y1:y2, x1:x2].copy())    \n",
    "        images.append(img)\n",
    "    \n",
    "    renormalized_cam = np.max(np.float32(images), axis = 0)\n",
    "    renormalized_cam = scale_cam_image(renormalized_cam)\n",
    "    eigencam_image_renormalized = show_cam_on_image(image_float_np, renormalized_cam, use_rgb=True)\n",
    "    image_with_bounding_boxes = draw_boxes(boxes, labels, classes, eigencam_image_renormalized)\n",
    "    return image_with_bounding_boxes\n",
    "\n",
    "Image.fromarray(renormalize_cam_in_bounding_boxes(boxes, image_float_np, grayscale_cam))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
